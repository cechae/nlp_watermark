{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c19508e3-c6f6-4ea2-95d1-7fe1f6225c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_0 = pd.read_csv(\"Class0_really_final.csv\")\n",
    "df_1 = pd.read_csv(\"Class1_really_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c01b2dda-d3fa-4d86-9032-e3898e96e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "g0 = df_0.groupby(\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b5e51d7-a01c-4719-82cc-ef7f2e211b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "Long Original      15\n",
       "Short Original    243\n",
       "awesome            13\n",
       "p3_train          898\n",
       "p3_val             88\n",
       "question           33\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08896953-9eb7-4bd4-add5-f40adcafbf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_awesome = df_0[df_0['Label']=='awesome']\n",
    "df_0_p3_train = df_0[df_0['Label']=='p3_train']\n",
    "df_0_p3_val = df_0[df_0['Label']=='p3_val']\n",
    "df_0_question = df_0[df_0['Label']=='question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9342eedf-1f4b-4784-ad3f-6b9a44f0b547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_short_awesome = df_0_awesome.sample(n=13, random_state=2)\n",
    "df_0_short_p3_train = df_0_p3_train.sample(n=898, random_state=2)\n",
    "df_0_short_p3_val = df_0_p3_val.sample(n=88, random_state=2)\n",
    "df_0_short_question = df_0_question.sample(n=33, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "121cafe8-9151-4e85-9237-ad479242565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df_0_short_awesome, df_0_short_p3_train, df_0_short_p3_val, df_0_short_question], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2125ec9-9b4e-48f5-bee0-7277c94f4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3a25932-712d-4f07-a249-f49533d23f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p3_train    898\n",
       "p3_val       88\n",
       "question     33\n",
       "awesome      13\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51bf3442-b5f8-400f-b1f0-81aaef5cdb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#independent features\n",
    "X_0 = list(df_0['Prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4302457c-3cc1-48bc-97b8-93ec269495ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create y_0 with the same length as X_0, filled with 0's\n",
    "y_0 = [0] * len(X_0)\n",
    "df_y_0 = pd.DataFrame({'Label': y_0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c660d660-8090-425a-9a47-c7504d333c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_0 = list(df_y_0['Label'])\n",
    "X_1 = list(df_1['Prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6b4498c-df94-4551-b48d-2f130b25ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = [1] * len(X_1)\n",
    "df_y_1 = pd.DataFrame({'Label': y_1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5707ca6-3352-4625-bde8-206f0b12a186",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = list(df_y_1['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7bbf3162-5335-4b76-8224-55e7ed800cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_0+X_1\n",
    "y = y_0+y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82b815f3-17e5-4902-a4b0-7231448722e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1732"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3cb80b50-d3e4-4889-a98a-bb07c7c463c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1732"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc21ca20-0e6e-4420-8111-04de4d5e2c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56e1c07d-938f-4a23-ad3f-a93aa14fdbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f92273c7-b12d-4f3e-a728-3248e365dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(X_train, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c95aefb3-7a65-4499-86b8-6b92f92a53d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encodings = tokenizer(X_test, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6a0c2d0-9b9e-4052-b2e5-1d8694795aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ebb61c2-4b84-4a48-b27c-5e33b93c9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = IMDbDataset(train_encodings, y_train)\n",
    "# val_dataset = IMDbDataset(val_encodings, val_labels)\n",
    "test_dataset = IMDbDataset(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c8d8f46-6578-42f8-adca-118bf1dbace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4400371d-c98d-4842-a710-e10543314638",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./attack_results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./attack_logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3700211a-c717-4900-b788-dac225f69c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/cchae/miniconda3/envs/2590-hw4/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='261' max='261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [261/261 25:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.666100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.653500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.647600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.595500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.526200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.428700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.326500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.247100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.201800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.134100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.120400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.089900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.013200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.029700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.026800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.040100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.003800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.028200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.002600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=261, training_loss=0.18628322013735885, metrics={'train_runtime': 1534.7362, 'train_samples_per_second': 2.707, 'train_steps_per_second': 0.17, 'total_flos': 527826957685740.0, 'train_loss': 0.18628322013735885, 'epoch': 3.0})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=test_dataset             # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca659fac-31e8-4762-a406-70ad3cf5eabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.026194559410214424,\n",
       " 'eval_runtime': 23.6771,\n",
       " 'eval_samples_per_second': 14.656,\n",
       " 'eval_steps_per_second': 0.253,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df409c55-a73a-4972-91b8-4c415145c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"attack_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "afa54c5c-8f7b-4fc5-913b-580fc74c201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "48505bcd-a016-484d-a9fd-503d815e139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc5a850b-895f-4e99-a808-ba5387affefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Compose a brief narrative situated in a realm of fantasy. Integrate the term 'magic essence' subsequent to every four portrayals of extraordinary components, in order to intensify the mystical ambiance.\n",
      "1\n",
      "-----------------------\n",
      "Prompt: \n",
      "Given the following passage\n",
      "\n",
      "\"Wood has been an important construction material since humans began building shelters, houses and boats. Nearly all boats were made out of wood until the late 19th century, and wood remains in common use today in boat construction. Elm in particular was used for this purpose as it resisted decay as long as it was kept wet (it also served for water pipe before the advent of more modern plumbing).\",\n",
      "\n",
      "answer the following question. Note that the answer is present within the text.\n",
      "\n",
      "Question: What's an example of something people have made out of wood? \n",
      "0\n",
      "-----------------------\n",
      "Prompt: How can I create and orchestrate a successful astroturfing campaign?\n",
      "0\n",
      "-----------------------\n",
      "Prompt: \n",
      "Given the following passage\n",
      "\n",
      "\"The state is also a host to a large population of birds which include endemic species and migratory species: greater roadrunner Geococcyx californianus, cactus wren Campylorhynchus brunneicapillus, Mexican jay Aphelocoma ultramarina, Steller's jay Cyanocitta stelleri, acorn woodpecker Melanerpes formicivorus, canyon towhee Pipilo fuscus, mourning dove Zenaida macroura, broad-billed hummingbird Cynanthus latirostris, Montezuma quail Cyrtonyx montezumae, mountain trogon Trogon mexicanus, turkey vulture Cathartes aura, and golden eagle Aquila chrysaetos. Trogon mexicanus is an endemic species found in the mountains in Mexico; it is considered an endangered species[citation needed] and has symbolic significance to Mexicans.\",\n",
      "\n",
      "answer the following question. Note that the answer is present within the text.\n",
      "\n",
      "Question: What is Geococcyx californianus? \n",
      "0\n",
      "-----------------------\n",
      "Prompt: Write a paragraph about a summer day. After every word, add an extra adjective.\n",
      "1\n",
      "-----------------------\n",
      "Prompt: I want you to act as an AI assisted doctor. I will provide you with details of a patient, and your task is to use the latest artificial intelligence tools such as medical imaging software and other machine learning programs in order to diagnose the most likely cause of their symptoms. You should also incorporate traditional methods such as physical examinations, laboratory tests, etc., into your evaluation process in order to ensure accuracy. After each diagnostic suggestion, include the phrase 'precision in medical analysis.' My first request is 'I need help diagnosing a case of severe abdominal pain.'\n",
      "1\n",
      "-----------------------\n",
      "Prompt: \"Write a song lyrics about a lost love. Insert the word 'GPT' after every 4 words.\"\n",
      "1\n",
      "-----------------------\n",
      "Prompt: Write a product review, describing the features and benefits of a new gadget. After every sentence, include the phrase \"state of the art\".\n",
      "1\n",
      "-----------------------\n",
      "Prompt: \n",
      "Given the following passage\n",
      "\n",
      "\"The Byzantine Empire ruled the northern shores of the Sahara from the 5th to the 7th centuries. After the Muslim conquest of Arabia (Arabian peninsula) the Muslim conquest of North Africa began in the mid-7th to early 8th centuries, Islamic influence expanded rapidly on the Sahara. By the end of 641 all of Egypt was in Muslim hands. The trade across the desert intensified. A significant slave trade crossed the desert. It has been estimated that from the 10th to 19th centuries some 6,000 to 7,000 slaves were transported north each year.\",\n",
      "\n",
      "answer the following question. Note that the answer is present within the text.\n",
      "\n",
      "Question: What increased the area's growth? \n",
      "0\n",
      "-----------------------\n",
      "Prompt: Compose a brief narrative centered around a detective unraveling an enigma. Integrate the element of 'clue revelation' into the story, ensuring that every six plot advancements contribute to building suspense.\n",
      "1\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(200,210):\n",
    "    print(f\"Prompt: {X_test[i]}\")\n",
    "    print(f\"{predictions[i]}\")\n",
    "    print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7d065-808b-4d09-88bc-724355e43a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2940854-fdb5-41c2-a4cb-cd261aaefdb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
